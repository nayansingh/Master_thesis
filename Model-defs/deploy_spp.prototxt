name: "ImageNet_Zeiler"
input: "data"
input_dim: 8
input_dim: 3
input_dim: 224
input_dim: 224

# ------------------------ layer 1 -----------------------------
layers {
   name: "conv1"
   type: CONVOLUTION
   bottom: "data"
   top: "conv1"
   convolution_param {
	   num_output: 96
	   kernel_size: 7
	   pad: 1
	   stride: 2
   }
}

layers {
   name: "relu1"
   type: RELU
   bottom: "conv1"
   top: "conv1"
}

layers {
    name: "norm1"
    type: LRN
    bottom: "conv1"
    top: "norm1"
	lrn_param{
		local_size: 3
		alpha: 0.00005
		beta: 0.75
		norm_region: WITHIN_CHANNEL
	}
}

layers {
   name: "pool1"
   type: POOLING
   bottom: "norm1"
   top: "pool1"
   pooling_param{
	   kernel_size: 3
	   stride: 2
	   pool: MAX
   }
}


# --------------------------- layer 2 ------------------------
layers {
   name: "conv2"
   type: CONVOLUTION
   bottom: "pool1"
   top: "conv2"
   convolution_param{
	   num_output: 256
	   kernel_size: 5
	   pad: 0
	   stride: 2
   }
}

layers {
   name: "relu2"
   type: RELU
 bottom: "conv2"
 top: "conv2"
}

layers {
    name: "norm2"
    type: LRN
	lrn_param{
		local_size: 3
		alpha: 0.00005
		beta: 0.75
		norm_region: WITHIN_CHANNEL
	}
  bottom: "conv2"
  top: "norm2"
}

layers {
   name: "pool2"
   type: POOLING
   pooling_param{
	   kernel_size: 3
	   stride: 2
	   pool: MAX
   }
 bottom: "norm2"
 top: "pool2"
}


#-----------------------layer 3-------------------------
layers {
   name: "conv3"
   type: CONVOLUTION
   convolution_param{
	   num_output: 384
	   kernel_size: 3
	   pad: 1
	   stride: 1
   }
 bottom: "pool2"
 top: "conv3"
}

layers {
   name: "relu3"
   type: RELU
 bottom: "conv3"
 top: "conv3"
}

#-----------------------layer 4-------------------------
layers {
   name: "conv4"
   type: CONVOLUTION
   convolution_param{
	   num_output: 384
	   kernel_size: 3
	   pad: 1
	   stride: 1
   }
 bottom: "conv3"
 top: "conv4"
}

layers {
   name: "relu4"
   type: RELU
 bottom: "conv4"
 top: "conv4"
}

#-----------------------layer 5-------------------------
layers {
   name: "conv5"
   type: CONVOLUTION
   convolution_param{
	   num_output: 256
	   kernel_size: 3
	   pad: 1
	   stride: 1
   }
 bottom: "conv4"
 top: "conv5"
}

layers {
   name: "relu5"
   type: RELU
 bottom: "conv5"
 top: "conv5"
}

#--------------------------layer spm------------------------

layers {
   name: "pool5_spm6"
   type: POOLING
   pooling_param{
		kernel_size: 3
		stride: 2
		pool: MAX
   }
 bottom: "conv5"
 top: "pool5_spm6"
}
layers {
   name: "pool5_spm6_flatten"
   type: FLATTEN
 bottom: "pool5_spm6"
 top: "pool5_spm6_flatten"
}
layers {
   name: "pool5_spm3"
   type: POOLING
   pooling_param{
		kernel_size: 5
		stride: 4
		pool: MAX
   }
 bottom: "conv5"
 top: "pool5_spm3"
}
layers {
   name: "pool5_spm3_flatten"
   type: FLATTEN
 bottom: "pool5_spm3"
 top: "pool5_spm3_flatten"
}
layers {
   name: "pool5_spm2"
   type: POOLING
   pooling_param{
		kernel_size: 7
		stride: 7
		pool: MAX
   }
 bottom: "conv5"
 top: "pool5_spm2"
}
layers {
   name: "pool5_spm2_flatten"
   type: FLATTEN
 bottom: "pool5_spm2"
 top: "pool5_spm2_flatten"
}
layers {
   name: "pool5_spm1"
   type: POOLING
   pooling_param{
		kernel_size: 13
		stride: 13
		pool: MAX
   }
 bottom: "conv5"
 top: "pool5_spm1"
}
layers {
   name: "pool5_spm1_flatten"
   type: FLATTEN
 bottom: "pool5_spm1"
 top: "pool5_spm1_flatten"
}
layers {
   name: "pool5_spm"
   type: CONCAT
   concat_param{
		concat_dim: 1
   }
 bottom: "pool5_spm1_flatten"
 bottom: "pool5_spm2_flatten"
 bottom: "pool5_spm3_flatten"
 bottom: "pool5_spm6_flatten"
 top: "pool5_spm"
}


#--------------------------layer 6------------------------
layers {
   name: "fc6"
   type: INNER_PRODUCT
   inner_product_param{
	   num_output: 4096
   }
 bottom: "pool5_spm"
 top: "fc6"
}
layers {
   name: "relu6"
   type: RELU
 bottom: "fc6"
 top: "fc6"
}
layers {
    name: "drop6"
    type: DROPOUT
	dropout_param{
		dropout_ratio: 0.5
	}
  bottom: "fc6"
  top: "fc6"
}
#--------------------------layer 7------------------------
layers {
   name: "fc7"
   type: INNER_PRODUCT
   inner_product_param{
	   num_output: 4096
   }
 bottom: "fc6"
 top: "fc7"
}
layers {
   name: "relu7"
   type: RELU
 bottom: "fc7"
 top: "fc7"
}
layers {
    name: "drop7"
    type: DROPOUT
	dropout_param{
		dropout_ratio: 0.5
	}
  bottom: "fc7"
  top: "fc7"
}

#--------------------------layer 8------------------------
layers {
   name: "fc8"
   type: INNER_PRODUCT
   inner_product_param{
	   num_output: 26
   }
 bottom: "fc7"
 top: "fc8"
}

#-----------------------output------------------------
layers {
   name: "prob"
type: SOFTMAX
 bottom: "fc8"
 top: "prob"
}
